
#sql-source  依赖 ng-jar @see https://github.com/keedio/flume-ng-sql-source

agent.sources = sql-source
agent.channels=c1
agent.sinks = es

##--------------------------------
##sources
##--------------------------------
agent.sources.sql-source.type = org.keedio.flume.source.SQLSource
agent.sources.sql-source.hibernate.connection.url = jdbc:oracle:thin:@192.168.1.219:1521:orcl
# Hibernate Database connection properties
agent.sources.sql-source.hibernate.connection.user = system
agent.sources.sql-source.hibernate.connection.password = oracle
agent.sources.sql-source.hibernate.connection.autocommit = true
agent.sources.sql-source.hibernate.dialect = org.hibernate.dialect.Oracle9Dialect
agent.sources.sql-source.hibernate.connection.driver_class = oracle.jdbc.driver.OracleDriver

#agent.sources.sql-source.table = employee1
# Columns to import to kafka (default * import entire row)
agent.sources.sql-source.columns.to.select = *

# Increment column properties
agent.sources.sql-source.incremental.column.name = id

# Increment value is from you want to start taking data from tables (0 will import entire table)
agent.sources.sql-source.incremental.value = 0

# Query delay, each configured milisecond the query will be sent
agent.sources.sql-source.run.query.delay=10000

# Status file is used to save last readed row
agent.sources.sql-source.status.file.path = ./conf/sql-source/
agent.sources.sql-source.status.file.name = oracle-status.status

#Custom query
agent.sources.sql-source.custom.query = SELECT * FROM flume_ng_sql_es_test WHERE 1=1
agent.sources.sql-source.batch.size = 1000
agent.sources.sql-source.max.rows = 10000



##--------------------------------
##channels
##--------------------------------

agent.channels.c1.type = memory
agent.channels.c1.capacity = 20
agent.channels.c1.transactionCapacity = 10
#agent.channels.c1.byteCapacityBufferPercentage = 20
#agent.channels.c1.byteCapacity = 800


##--------------------------------
##sinks
##--------------------------------

agent.sinks.es.type=org.apache.flume.sink.elasticsearch.ElasticSearchSink
agent.sinks.es.batchSize=100
agent.sinks.es.hostNames=127.0.0.1:9300
agent.sinks.es.indexType = sql-source-test
agent.sinks.es.indexName=sql-source-test
agent.sinks.es.clusterName=fusionskye
agent.sinks.es.serialiizer=org.apache.flume.sink.elasticsearch.ElasticSearchLogStashEventSerializer

# Bind the source and sink to the channel
agent.sources.sql-source.channels = c1
agent.sinks.es.channel = c1
