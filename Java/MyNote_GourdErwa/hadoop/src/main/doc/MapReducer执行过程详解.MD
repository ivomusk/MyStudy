
##Map 任务的执行过程详解

1.第一阶段是把输入文件按照一定的标准分片(InputSplit)，每个输入片的大小是固定的。
    默认情况下，输入片(InputSplit)的大小与数据块(Block)的大小是相同的。
    如果数据块(Block)的大小是默认值64MB，输入文件有两个，一个是32MB，一个是72MB。
    那么小的文件是一个输入片，大文件会分为两个数据块，那么是两个输入片。一共产生三个输入片。
    每一个输入片由一个Mapper进程处理。这里的三个输入片，会有三个Mapper进程处理。

2.第二阶段是对输入片中的记录按照一定的规则解析成键值对。
    有个默认规则是把每一行文本内容解析成键值对。“键”是每一行的起始位置(单位是字节)，“值”是本行的文本内容。

3.第三阶段是调用Mapper类中的map方法。第二阶段中解析出来的每一个键值对，调用一次map方法。
    如果有1000个键值对，就会调用1000次map方法。每一次调用map方法会输出零个或者多个键值对。

4.第四阶段是按照一定的规则对第三阶段输出的键值对进行分区。
    比较是基于键进行的。比如我们的键表示省份(如北京、上海、山东等)，那么就可以按照不同省份进行分区，同一个省份的键值对划分到一个区中。
    默认是只有一个区。分区的数量就是Reducer任务运行的数量。默认只有一个Reducer任务。

5.第五阶段是对每个分区中的键值对进行排序。
    首先，按照键进行排序，对于键相同的键值对，按照值进行排序。
    比如三个键值对<2,2>、<1,3>、<2,1>，键和值分别是整数。那么排序后的结果是<1,3>、<2,1>、<2,2>。
    如果有第六阶段，那么进入第六阶段；如果没有，直接输出到本地的linux文件中。

6.第六阶段是对数据进行归约处理，也就是reduce处理。
    键相等的键值对会调用一次reduce方法。经过这一阶段，数据量会减少。
    归约后的数据输出到本地的linxu文件中。本阶段默认是没有的，需要用户自己增加这一阶段的代码。


##Reducer 任务的执行过程详解

1.第一阶段是Reducer任务会主动从Mapper任务复制其输出的键值对。Mapper任务可能会有很多，因此Reducer会复制多个Mapper的输出。

2.第二阶段是把复制到Reducer本地数据，全部进行合并，即把分散的数据合并成一个大的数据。再对合并后的数据排序。

3.第三阶段是对排序后的键值对调用reduce方法。键相等的键值对调用一次reduce方法，每次调用会产生零个或者多个键值对。最后把这些输出的键值对写入到HDFS文件中。

    在整个MapReduce程序的开发过程中，我们最大的工作量是覆盖map函数和覆盖reduce函数。